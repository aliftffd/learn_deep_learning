{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tensor \n",
    "Creating tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar \n",
    "scalar = torch.tensor(8)\n",
    "scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 9],\n",
      "        [9, 3]])\n",
      "2\n",
      "tensor([9, 3])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "#Get tensor back as python int \n",
    "scalar.item()\n",
    "MATRIX = torch.tensor([[9,9],\n",
    "                       [9,3]])\n",
    "\n",
    "print(MATRIX)\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX[1])\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9, 9, 4],\n",
      "         [3, 3, 4],\n",
      "         [5, 6, 7]]])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Tensor \n",
    "TENSOR = torch.tensor([[[9,9,4],\n",
    "                       [3,3,4],\n",
    "                       [5,6,7]]])\n",
    "\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM TENSOR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors \n",
    "\n",
    "Why Random Tensors \n",
    "\n",
    "Random tensors are important because the way many neural networks learn is thath they start with tensors full of random numbers and the adjust those random numbers to better represent the data \n",
    "\n",
    "\"start with random numbers -> look at data -> update random numbers -> look at data -> update\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0096, 0.9565, 0.3148, 0.5884],\n",
       "        [0.7853, 0.3816, 0.1132, 0.5854],\n",
       "        [0.4365, 0.9452, 0.2532, 0.6910]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creater a random tensor with similar shape to image tensor \n",
    "\n",
    "random_img_tensor_size = torch.rand(size=(3,224,224))\n",
    "random_img_tensor_size.shape, random_img_tensor_size.ndim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_to_ten = torch.arange(start = 1, end = 11, step = 1) # Use torch.range()\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like \n",
    "\n",
    "ten_zero = torch.zeros_like(one_to_ten)\n",
    "ten_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing Tensor With Data Type \n",
    "\n",
    "**Note** Tensor datatype is one of the 3 big issues (error) with PyTorch & deep Learning: \n",
    "1. Tensors not right datatype \n",
    "2. Tensors nor right device \n",
    "3. tensors not on the right device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor \n",
    "\n",
    "float_32_tensor = torch.tensor([3.0, 4.0, 5.0], \n",
    "                               dtype=torch.float32, # mengatur data type apa yang di gunakan \n",
    "                               device=device, # device apa yang di gunakan\n",
    "                               requires_grad=True) # wheter or not to track gradients with this tensors operation \n",
    "\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4., 5.], device='cuda:0', dtype=torch.float16,\n",
       "       grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 16., 25.], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 4, 5],\n",
    "                             dtype =torch.int32,device=device) \n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Getting Information* (tensor Attributes)\n",
    "1. Tensors not right datatype - to do get dataype from a tensor, can use **'tensor.dtype'*** \n",
    "2. Tensors nor right device  - to get shape from a tensor, can use **'tensor.shape'**\n",
    "3. tensors not on the right device - to get device from a tensor, can use **'tensor.device'** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5842, 0.2355, 0.5840,  ..., 0.4394, 0.2238, 0.8040],\n",
       "         [0.6253, 0.2123, 0.1982,  ..., 0.6038, 0.1170, 0.8149],\n",
       "         [0.6273, 0.7306, 0.1288,  ..., 0.3458, 0.7228, 0.1424],\n",
       "         ...,\n",
       "         [0.5409, 0.0653, 0.2365,  ..., 0.6256, 0.3178, 0.5142],\n",
       "         [0.4649, 0.8726, 0.2242,  ..., 0.8241, 0.4701, 0.4163],\n",
       "         [0.4556, 0.4455, 0.2435,  ..., 0.3167, 0.7744, 0.8555]],\n",
       "\n",
       "        [[0.2004, 0.5241, 0.9759,  ..., 0.8785, 0.2864, 0.1746],\n",
       "         [0.6854, 0.4033, 0.4740,  ..., 0.8136, 0.5177, 0.9372],\n",
       "         [0.6565, 0.9598, 0.8090,  ..., 0.1049, 0.0391, 0.0755],\n",
       "         ...,\n",
       "         [0.6586, 0.4166, 0.3230,  ..., 0.2743, 0.8770, 0.6889],\n",
       "         [0.1053, 0.0372, 0.1134,  ..., 0.3379, 0.3193, 0.0288],\n",
       "         [0.3094, 0.1938, 0.3151,  ..., 0.5321, 0.5719, 0.9626]],\n",
       "\n",
       "        [[0.2414, 0.3346, 0.5878,  ..., 0.5424, 0.6406, 0.6494],\n",
       "         [0.2318, 0.6011, 0.5836,  ..., 0.5923, 0.1553, 0.9961],\n",
       "         [0.0493, 0.3652, 0.3020,  ..., 0.0687, 0.9981, 0.3654],\n",
       "         ...,\n",
       "         [0.3820, 0.2173, 0.6547,  ..., 0.2220, 0.4170, 0.2281],\n",
       "         [0.8702, 0.9248, 0.7062,  ..., 0.1711, 0.0675, 0.5519],\n",
       "         [0.8018, 0.6430, 0.6320,  ..., 0.3260, 0.3929, 0.4495]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand([3,24,16]).to(device)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5842, 0.2355, 0.5840,  ..., 0.4394, 0.2238, 0.8040],\n",
      "         [0.6253, 0.2123, 0.1982,  ..., 0.6038, 0.1170, 0.8149],\n",
      "         [0.6273, 0.7306, 0.1288,  ..., 0.3458, 0.7228, 0.1424],\n",
      "         ...,\n",
      "         [0.5409, 0.0653, 0.2365,  ..., 0.6256, 0.3178, 0.5142],\n",
      "         [0.4649, 0.8726, 0.2242,  ..., 0.8241, 0.4701, 0.4163],\n",
      "         [0.4556, 0.4455, 0.2435,  ..., 0.3167, 0.7744, 0.8555]],\n",
      "\n",
      "        [[0.2004, 0.5241, 0.9759,  ..., 0.8785, 0.2864, 0.1746],\n",
      "         [0.6854, 0.4033, 0.4740,  ..., 0.8136, 0.5177, 0.9372],\n",
      "         [0.6565, 0.9598, 0.8090,  ..., 0.1049, 0.0391, 0.0755],\n",
      "         ...,\n",
      "         [0.6586, 0.4166, 0.3230,  ..., 0.2743, 0.8770, 0.6889],\n",
      "         [0.1053, 0.0372, 0.1134,  ..., 0.3379, 0.3193, 0.0288],\n",
      "         [0.3094, 0.1938, 0.3151,  ..., 0.5321, 0.5719, 0.9626]],\n",
      "\n",
      "        [[0.2414, 0.3346, 0.5878,  ..., 0.5424, 0.6406, 0.6494],\n",
      "         [0.2318, 0.6011, 0.5836,  ..., 0.5923, 0.1553, 0.9961],\n",
      "         [0.0493, 0.3652, 0.3020,  ..., 0.0687, 0.9981, 0.3654],\n",
      "         ...,\n",
      "         [0.3820, 0.2173, 0.6547,  ..., 0.2220, 0.4170, 0.2281],\n",
      "         [0.8702, 0.9248, 0.7062,  ..., 0.1711, 0.0675, 0.5519],\n",
      "         [0.8018, 0.6430, 0.6320,  ..., 0.3260, 0.3929, 0.4495]]],\n",
      "       device='cuda:0')\n",
      "Tipe data dari tensor : torch.float32\n",
      "Shape dari tensor : torch.Size([3, 24, 16])\n",
      "device dari tensor : cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"Tipe data dari tensor : {some_tensor.dtype}\")\n",
    "print(f\"Shape dari tensor : {some_tensor.shape}\")\n",
    "print(f\"device dari tensor : {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor Operations) \n",
    "\n",
    "tensor operations incule : \n",
    "* addition \n",
    "* substraction \n",
    "* multiplication (element-wise)\n",
    "* division \n",
    "* matrix multiplication \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1,2,3]) # addition \n",
    "tensor + 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor / 10 # multiplication\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7650, 0.5885, 0.9052])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytoch built-in functions \n",
    "\n",
    "torch.add(tensor, torch.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multipication \n",
    "Two main ways of performing multiplication in neural networks and deep learning:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix mutliplication (dot product)\n",
    "\n",
    "There are two main rules that performing matrix mutliplication needs to satisfy:\n",
    "1. The **inner dimentions** must match:\n",
    "* '(3,2) @ (3,2)' won't work \n",
    "* '(2,3) @ (3,2)' will work \n",
    "* '(3,2) @ (2,3)' will work \n",
    "2. the resulting matrix has the sape of the **outer dimensions** \n",
    "* '(2,3) @ (3,2)' -> '(2,2)' \n",
    "* '(3,2) @ (2,3)' -> '(3,3)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(10,10),torch.rand(10,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000]) * tensor([0.1000, 0.2000, 0.3000])\n",
      "Equals : tensor([0.0100, 0.0400, 0.0900])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication \n",
    "print(tensor, \"*\" , tensor ) \n",
    "print(f\"Equals : {tensor.mul(tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor,tensor) # -> 1*1 + 2*2 + 3*3 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1400)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4.51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "value = 0 \n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 818 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1400)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "torch.matmul(tensor, tensor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common errors in deep learning: shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_a \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m      3\u001b[0m tensor_b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m) \n\u001b[1;32m----> 5\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(tensor_a,tensor_b)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)"
     ]
    }
   ],
   "source": [
    "# shape for matrix multipication \n",
    "tensor_a = torch.rand(3,4)\n",
    "tensor_b = torch.rand(3,4) \n",
    "\n",
    "torch.mm(tensor_a,tensor_b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a , tensor_a.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_a torch.Size([3, 4]), tensor B torch.Size([3, 4])\n",
      "New shape :tensor_a =torch.Size([4, 3]) (same shape as above), tensor_b.T = torch.Size([3, 4])\n",
      "Multiplying: torch.Size([4, 3]) @ torch.Size([3, 4]) inner dimensions must match\n",
      "Output: \n",
      "\n",
      "tensor([[0.7679, 0.1962, 0.1245, 0.4062],\n",
      "        [0.5379, 0.2817, 0.1229, 0.7300],\n",
      "        [0.6332, 0.2454, 0.0662, 0.5932],\n",
      "        [0.8586, 0.3474, 0.1686, 0.8496]])\n",
      "\n",
      "\n",
      "Output shape: torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes: tensor_a {tensor_a.shape}, tensor B {tensor_b.shape}\")  \n",
    "print(f\"New shape :tensor_a ={tensor_a.T.shape} (same shape as above), tensor_b.T = {tensor_b.shape}\")\n",
    "print(f\"Multiplying: {tensor_a.T.shape} @ {tensor_b.shape} inner dimensions must match\")\n",
    "print (\"Output: \\n\" )\n",
    "\n",
    "output = torch.matmul(tensor_a.T,tensor_b)\n",
    "\n",
    "print (output)\n",
    "print(\"\\n\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum, etc (tensor aggregation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor \n",
    "x = torch.arange(0,100,10)\n",
    "x.dtype "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the min \n",
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(30.2765))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mean-note: the torch.mean() function requires a tensor of float 32 datatype to work\n",
    "torch.mean(x.type(torch.float32)) , torch.std(x.type(torch.float32)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sum \n",
    "x.sum() , torch.sum(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the position min and max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the the position of min and max value using \"arg\" with min and max value accure \n",
    "x.argmin(), x.argmax() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4367, 0.3260, 0.3334],\n",
       "        [0.8506, 0.5995, 0.3290],\n",
       "        [0.6621, 0.2611, 0.8333]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(3,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), tensor(7))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmax(), y.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping,stacking,squeezing, and unsqueezing tensors \n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all 1 dimensions from a tensor\n",
    "* Unsqueeze - adda 1 dimension to a target tensor\n",
    "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor \n",
    "p = torch.arange(1., 10.)\n",
    "p , p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra dimension \n",
    "p_reshaped = p.reshape(1,9)\n",
    "p_reshaped , p_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view \n",
    "z = p.view(1, 9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change z changes p (because a view of a tensor shares the same memory as the original one \n",
    "z[:,0] = 5 \n",
    "z, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack the tensor each other \n",
    "p_stack = torch.stack([p,p,p,p], dim = 1) \n",
    "p_stack \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor sebelumnya : tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Shape tensor sebelumnya : torch.Size([1, 9])\n",
      "\n",
      "new tensor : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "shape new tensor : torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# toch.squeeze() - remove all single dimensions from a target tensor \n",
    "print(f\"Tensor sebelumnya : {p_reshaped}\") \n",
    "print(f\"Shape tensor sebelumnya : {p_reshaped.shape}\") \n",
    "\n",
    "# remove extra dimensions from p_reshaped \n",
    "p_squeezed = p_reshaped.squeeze() \n",
    "print(f\"\\nnew tensor : {p_squeezed}\") \n",
    "print(f\"shape new tensor : {p_squeezed.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previouse Target : tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previouse Target shape : torch.Size([9])\n",
      "\n",
      "new tensor : tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "shape new tensor : torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze () - add a single dimensions to a target tensor ata specific dim (dimensions) \n",
    "\n",
    "print(f\"Previouse Target : {p_squeezed}\") \n",
    "print(f\"Previouse Target shape : {p_squeezed.shape}\") \n",
    "\n",
    "#add an extra dimension with unsqueeze \n",
    "p_unsqueeze = p_squeezed.unsqueeze(dim = 0) \n",
    "print(f\"\\nnew tensor : {p_unsqueeze}\") \n",
    "print(f\"shape new tensor : {p_unsqueeze.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previouse shape : torch.Size([224, 224, 3])\n",
      "new shape : torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch permute - rearrange the dimensions of a target tensor in a specified order \n",
    "x_original = torch.rand(size  = (224,224,3)) # (height,width, colour_channels) \n",
    "\n",
    "# permute the original tensor to rearrange the axis (or dim) order \n",
    "x_permuted = x_original.permute(2,0,1) # shift axis 0-> 1 , 1 -> 2 , 2 -> 0 \n",
    "\n",
    "print(f\"Previouse shape : {x_original.shape}\") \n",
    "print(f\"new shape : {x_permuted.shape}\") # [colour_channels, height, width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original[0,0,0] = 0.8  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8000), tensor(0.8000))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_permuted[0,0,0] , x_original[0,0,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors) \n",
    "indexing with pytorch is similar to indexing with numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor \n",
    "x = torch.arange(1,10).reshape(1,3,3) \n",
    "x, x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index the new tensor \n",
    "x[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing on middle bracket \n",
    "x[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket (last dimension) \n",
    "x[0][2][2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 6]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#can also use \":\" to select \"all\" of a target dimension \n",
    "x[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all values of 0th and 1st dimension but only index 2of 2nd dimension \n",
    "x[:,:,2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,1] # Get all values of the 0 dimension but only the 1 index value of 1st and 2nd dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & numpy \n",
    "\n",
    "Numpy is a popular scientific python numerical computing library. and because of this, PyTorch has fucntionally to interect with it. \n",
    "* Data in NumPy, want in PyTorch tensor -> 'torch.from_numpy(ndarray)'\n",
    "* Pytorch tensor -> NumPy -> 'torch.Tensor.numpy()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor \n",
    "\n",
    "array = np.arange(1.0, 8.0) \n",
    "tensor = torch.from_numpy(array) # dtype data array numpy akan mengikut ke tensor \n",
    "array,tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype # default numpy dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array + 1 # Penggantian pada original array (numpy) tidak berpengaruh ke tensor \n",
    "array , tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5254, 0.8711, 0.6061, 0.1587, 0.2317, 0.9228, 0.9406]),\n",
       " array([0.5253649 , 0.8710727 , 0.60606724, 0.15874553, 0.23173422,\n",
       "        0.92284536, 0.94058114], dtype=float32))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor to numpy \n",
    "tensor = torch.rand(7) \n",
    "numpy_tensor = tensor.numpy() \n",
    "tensor,numpy_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5253649 , 0.8710727 , 0.60606724, 0.15874553, 0.23173422,\n",
       "        0.92284536, 0.94058114], dtype=float32),\n",
       " tensor([1.5254, 1.8711, 1.6061, 1.1587, 1.2317, 1.9228, 1.9406]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor + 1 # Penggantian pada  tensor original  tidak berpengaruh ke array (numpy)\n",
    "numpy_tensor, tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducbility (Trying to take random out of random) \n",
    "\n",
    "in short how a nural network learns : \n",
    "\n",
    "'Start with random numbers -> tensor operations -> update random numbers to try and make them better of the data -> again -> again -> again ...' \n",
    "\n",
    "to reduce a randomness in Neural networks and PyTorch comes the concept of a **random seed**\n",
    "essentially what the random seed dose is \"flavour\" the randomness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0330, 0.0142, 0.5117, 0.0884],\n",
      "        [0.4532, 0.1579, 0.1224, 0.2373],\n",
      "        [0.9192, 0.8339, 0.8619, 0.5706]])\n",
      "tensor([[0.9736, 0.7819, 0.7224, 0.2185],\n",
      "        [0.5290, 0.5891, 0.4357, 0.1796],\n",
      "        [0.2670, 0.1805, 0.5404, 0.2218]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Crate two Random Tensor \n",
    "random_tensor_A = torch.rand(3,4) \n",
    "random_tensor_B = torch.rand(3,4) \n",
    "\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B) \n",
    "print(random_tensor_A == random_tensor_B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensor \n",
    "\n",
    "# set_random seed --> gunanya ini itu supaya tidak terlalu random tensornya \n",
    "RANDOM_SEED = 42 \n",
    "\n",
    "torch.manual_seed(RANDOM_SEED) # hanya bisa di lakukan per 1 baris \n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4) \n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D) \n",
    "print(random_tensor_C == random_tensor_D) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Tensors and Pytorch on GPU for running it faster \n",
    "\n",
    "GPUs == faster computaion on numbers **CUDA** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting A GPU \n",
    "* using google colab\n",
    "* Your own GPU\n",
    "* USe cloud computing - GCP,AWS,Azure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
